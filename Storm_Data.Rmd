---
title: "Economic Consequences & Population Health Hazards of Severe Weather"
author: "EHarris"
date: "6/05/2017"
output: 
  html_document: 
    keep_md: yes
---

## Load anticipated packages to be used throughout Course 5 Project 1
```{r setup, include=FALSE}
ipak <- function(pkg){
      new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
      if (length(new.pkg)) 
            install.packages(new.pkg, dependencies = TRUE)
      sapply(pkg, require, character.only = TRUE)
}

### Package Usage
packages <- c("plyr", "dplyr", "data.table", "dtplyr", "lubridate", "ggplot2",
                  "scales", "reshape2", "knitr", "cacher", "stringr")
ipak(packages)
```

### Analysis Synopsis
Due to the different types, and serverity, of weather experienced throughout a country, there is a desire to understand weather events that create the greatest economic consequences or most hazardous with respect to population health.  

We will be using data provided by the National Oceanic and Atmospheric Administration (NOAA) to help answer these questions.  Economic consequences are measured by the amount of damage, property and/or crop, that is associated with each event type.  The population health hazard is measured by the number of fatalities and/or injuries with an event.  The number of fatalities will be the primary metric for determining the population health hazard.

### Data Processing  
A first step to our analysis is reading the data into R from the working directory. The data provided is a zipped csv file.  We unzip and read into R using read.csv file.  The code to read in the file, as well as a couple summaries of the data.

##### Read zipped csv file into R
```{r read_storm_data, include = TRUE, cache = TRUE}
StormData <- read.csv("repdata-data-StormData.csv.bz2", header = TRUE, sep = ",",
                        quote = "\"", dec = ".")

##### A quick overview of the data in this file:
dim(StormData)

str(StormData)
```

##### Create Econonmic Consequencences metric for each event, event type & refnum
To facilitate analysis, it is necessary to modify the orginal data in some cases.  As an example, the dollar amounts for property damage are expressed in different denomiations (e.g. thousand vs. millions of dollars).  It is important to define a consistent measure so that dollars can be combined, or summed, for different levels of aggregation, as appropriate.
```{r economic_measure, include = TRUE}
StormData$economic <- StormData$PROPDMG * ifelse(StormData$PROPDMGEXP == "K", 1000,
                              ifelse(StormData$PROPDMGEXP == "M", 1000000,
                              ifelse(StormData$PROPDMGEXP == "B", 1000000000, 1))) +
                        StormData$CROPDMG * ifelse(StormData$CROPDMGEXP == "K", 1000,
                              ifelse(StormData$CROPDMGEXP == "M", 1000000,
                              ifelse(StormData$CROPDMGEXP == "B", 1000000000, 1)))
```

##### Define period for aggregating measurement data, population health & economic
A second area that requires some clean-up are the dates and times at the beginning and 
end of an event.  From documentation provided by the National Westher Service, some notes about the time of an event,

"In general, the time of an event, as it appears in the header-strip, is the time when 
the event reached locally, regionally, or nationally established advisory or warning criteria (exceptions defined in Section 2.3.1). The event time could be the single time that a peak wind gust of 65 knots (75 mph) occurred, or it could be beginning and ending times of a 10-minute shower of large, damaging hailstones. If the time of the event in 
the header-strip is a broad guesstimate,then it should be indicated as such in the event narrative."

For our analysis, the specific event times is not critical to assessing the hazard to population health or the amount of economic consequences.  The results will summarized to a calendar year based on BGN_DATE in the data provided.  In addition to converting BGN_DATE to a date format, we are adding a 'YEAR' column.
```{r event_dates, include = TRUE}

StormData$BGN_DATE <- mdy_hms(StormData$BGN_DATE)
StormData$BGN_YEAR <- year(StormData$BGN_DATE)

hour <- as.numeric(substr(StormData$BGN_TIME, 1, 2))
minute <- substr(StormData$BGN_TIME, 3, 4)
ampm <- ifelse(hour > 12, "PM", "AM")
zone <- StormData$TIME_ZONE
hour <- substr(paste("00", hour, sep = ""),min(length(hour)+1,3),min(length(hour)+2, 4))

time_hm <- strptime(paste(hour, ":", minute, " ", ampm, sep = ""),
                        format = "%I:%M %p", tz = "")
StormData$BGN_TIME <- struc
```

## Item 1: Code for reading in the dataset and/or processing the data
###   Step 1: Read csv file into R
```{r fileload, include = TRUE}
activity <- read.csv("activity.csv", header = TRUE, sep = ',',
                              colClasses = c("numeric", "character", "integer"))
```

###   Step 2: Process data to address other parts of assignment
```{r iniital_processing, include = TRUE}
activity$date <- strptime(activity$date, "%Y-%m-%d")
activity$day <- weekdays(activity$date)
activity$daytype <- ifelse(activity$day %in% c("Saturday", "Sunday"), "Weekend", "Weekday")
activity <- select(activity, daytype, day, date, interval, steps)
dates <- as.data.frame(as.Date(unique(activity$date)))
colnames(dates)[1] <- "date"
daterange = c(seq(min(dates$date), max(dates$date), by = 6))
```

## Item 2. Histogram of the total number of steps taken each day.  Two steps:  
### Step 1: Calculate total steps each day (remove missing, NA, values for steps) 
```{r total_steps_per_day, include = TRUE}
activity.clean <- subset(activity, !is.na(steps))
steps.a.day <- aggregate(activity.clean$steps, 
                        list(date = as.Date(activity.clean$date)), sum)
colnames(steps.a.day) <- c("date", "steps")
```

### Step 2: Plot histogram reflecting total number of steps per day
```{r steps_per_day_hist, fig.keep = "all", fig.show = "asis", fig.path = 'figure/'}
theme_update(plot.title = element_text(hjust = 0.5))
ggplot(steps.a.day, aes(x = steps)) +
      geom_histogram(binwidth = 1000, fill = "blue") +
      labs(title = "Total Steps per Day") +
      labs(x = "Steps a Day", y = "Frequency (# Days)")
```

## Item 3a: Mean & Median steps per day (excludes missing, NA, values)
```{r mean_median_steps_per_day, include = TRUE}
meansteps <- mean(steps.a.day$steps, na.rm = TRUE)
mediansteps <- median(steps.a.day$steps, na.rm = TRUE)
mean.median.steps <- data.frame("Mean Steps" = meansteps, "Median Steps" = mediansteps)
mean.median.steps
```

## Item 4a: Time series (day of week) plot of the average number of steps taken
```{r mean_steps_day_of_week, fig.keep = "all", fig.show = "asis", fig.path = 'figure/'}
mean.steps.day <- aggregate(steps ~ day, data = activity, 
                                    FUN = function(x) mean=mean(x))
mean.steps.day$day <- factor(mean.steps.day$day,
                        levels = c("Monday", "Tuesday", "Wednesday", "Thursday",
                                   "Friday","Saturday", "Sunday"))

theme_update(plot.title = element_text(hjust = 0.5))
qplot(x = day, y = steps, data = mean.steps.day, group = 7,  
      geom = c("point", "line"),
      xlab = "Day of Week", ylab = "Average Number of Steps",
      main = "Average Steps for each Day of Week")
```


## Item 4b: Time series (5-minute interval) plot of the average number of steps taken
```{r mean_steps_5min_interval, fig.keep = "all", fig.show = "asis", fig.path = 'figure/'}
mean.steps.interval <- aggregate(steps ~ interval, data = activity.clean, 
                                    FUN = function(x) mean=mean(x))

theme_update(plot.title = element_text(hjust = 0.5))
qplot(x = interval, y = steps, data = mean.steps.interval, group = 288,  
      geom = c("point", "line"),
      xlab = "5-Minute Interval", ylab = "Average Number of Steps",
      main = "Average Steps for each 5-Minute Interval")
```

## Item 5: 5-munite interval with maximum average number of steps  
```
Identifying the 5-minute interval with the highest average number of steps is  
performed in 3 steps.  Step 1 calculates the average number of steps for each  
5-minute interval.  Theser results are then sorted in decreasing order based  
on average number of steps, Step 2.  The final step, Step 3, is selecting the  
first row, which represents the highest average steps -- interval 835 with  
average steps = 206.1698.
```
### R Code performing each of these steps
```{r mean_steps_each5, include = TRUE}
steps.each.5min <- aggregate(steps ~ interval, data = activity,
                                    FUN = function(x) meansteps=mean(x))
steps.each.5min <- steps.each.5min[order(steps.each.5min$steps, decreasing = TRUE),]
steps.each.5min[1,]
```

## Item 6: Code to describe and show a strategy for imputing missing data
```
To impute a value that best reflects a missign value there are two parameters  
to be considered: 1) day of week and 2) interval.  We will replace each  
missing value with applicable imputed value.  
```
### Step 1: Calculate the mean steps for each day of week + interval combination  
#### NOTE:  Results are rounded, create integer, as partial steps are not counted.
```{r mean_steps_day_interval, include = TRUE}
mean.day.interval <- aggregate(steps ~ day + interval, data = activity,
                              FUN = function(x) mean=round(mean(x), digits = 0))
mean.day.interval <- select(mean.day.interval, day, interval, steps)
```

### Step 2: Identify missing values then replace with the imputed value.  
```
This, too, is completed in multiple steps.  The first step is to subset  
the missing values from observations with values.  A second step is to replace  
missing values with imputed values.  The final step is to combine the data  
sets with imputed values to those observations with actula values.  
```

#### Step 2a: Create data subsets, missing values and non-missing values
##### Missing values in data set activity.isna will be replaced by imputed values
```{r subset_missing, include = TRUE}
activity.isna <- subset(activity, is.na(steps))
activity.isna <- select(activity.isna, daytype, day, date, interval)
activity.isna <- activity.isna[order(activity.isna[,3],
                                         activity.isna[,4]),]

head(activity.isna)
```

#### Step 2b: Replace missign values with imputed values (merge function)
```{r subset_replace_missing, include = TRUE}
activity.impute <- merge(activity.isna, mean.day.interval, by = c("day","interval"))
activity.impute <- activity.impute[order(activity.impute$date,
                                         activity.impute$interval),]

head(activity.impute)
```

#### Step 2c: Combine, rbind(), imputed observations with actual observations
```{r combine_impute_actual, include = TRUE}
activity.total <- rbind(activity.clean, activity.impute)
activity.total <- activity.total[order(activity.total[,3], activity.total[,4]),]
```

#### Step 2d: Mean / Median steps after including imputed values
```{r impute_mean_median_steps_day, include = TRUE}
steps.impute.day <- aggregate(activity.total$steps, 
                        list(date = as.Date(activity.total$date)), sum)
colnames(steps.impute.day) <- c("date", "steps")
meansteps2 <- mean(steps.impute.day$steps, na.rm = TRUE)
mediansteps2 <- median(steps.impute.day$steps, na.rm = TRUE)
mean.median.steps2 <- data.frame("Mean Steps" = meansteps, "Median Steps" = mediansteps)
mean.median.steps2
```

## Item 7: Histogram of total steps each day after missing values are imputed
```
This is done in two steps.  The first step is simply calculating the total  
number of steps for each day.  The second, and final, step is creating a  
histogram of the number of steps for each day.  
```

### Step 1: Calculate total number of steps for each day, including imputed
```{r total_steps_with_imputed, include = TRUE}
impute.total.steps <- aggregate(activity.total$steps, 
                        list(date = as.Date(activity.total$date)), sum)
colnames(impute.total.steps) <- c("date", "steps")
```

### Step 2: Plot histogram reflecting total number of steps per day
```{r impute_steps_day_hist, fig.keep = "all", fig.show = "asis", fig.path = 'figure/'}
theme_update(plot.title = element_text(hjust = 0.5))
ggplot(impute.total.steps, aes(x = steps)) +
      geom_histogram(binwidth = 1000, fill = "blue") +
      labs(title = "Total Steps per Day") +
      labs(x = "Steps a Day", y = "Frequency (# Days)")
```

### Item 8: Panel plot of average number of steps per 5-minute interval  
#### A comparison of weekdays and weekend
```{r panel_plot, fig.keep = "all", fig.show = "asis", fig.path = 'figure/'}
mean.steps.daytype <- aggregate(steps ~ daytype + interval, data = activity,
                                                FUN = function(x) mean=mean(x))
mean.wday <- subset(mean.steps.daytype, daytype == "Weekday")
mean.wend <- subset(mean.steps.daytype, daytype == "Weekend")
min.yrange <- round(min(mean.steps.daytype$steps),0)
max.yrange <- round(max(mean.steps.daytype$steps),0)
yrange <- range(seq(from = min.yrange, to = max.yrange, by = 50))
par(mfrow = c(2, 1), mar = c(4, 4, 2, 1), oma = c(0, 0, 2, 0))
plot(mean.wday$interval, mean.wday$steps, pch = 20, type = "l",
                        xlim = range(0,2500), ylim = yrange, xlab = "Interval", 
                        ylab = "Avg Number of Steps", main = "Weekday")
plot(mean.wend$interval, mean.wend$steps, pch = 20, type = "l",
                        xlim = range(0,2500), ylim = yrange, xlab = "Interval",
                        ylab = "Avg Number of Steps", main = "Weekend")
```
